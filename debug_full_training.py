# Debug del training loop COMPLETO incluyendo _cfr_step_pure
import jax
import jax.numpy as jnp
from poker_bot.core.trainer import _cfr_step_pure, TrainerConfig

print("ğŸ” FULL TRAINING LOOP DEBUG:")
print("=" * 50)

# Setup inicial idÃ©ntico al trainer real - LEER DESDE YAML
config = TrainerConfig.from_yaml('config/training_config.yaml')

print(f"ğŸ“Š Config:")
print(f"  Learning rate: {config.learning_rate}")
print(f"  Batch size: {config.batch_size}")

# Estado inicial - usar las dimensiones correctas del config
regrets = jnp.zeros((config.max_info_sets, 9))
strategy = jnp.ones((config.max_info_sets, 9)) / 9

print(f"\nğŸ¯ Info Set despuÃ©s de modulo:")
target_info_set = 26027 % config.max_info_sets  # Aplicar mismo mapeo que bucketing
print(f"  Original: 26027 â†’ Mapped: {target_info_set}")
initial_regrets = regrets[target_info_set]
print(f"  Initial regrets: {jnp.max(jnp.abs(initial_regrets)):.6f} (deberÃ­a ser 0)")

# Ejecutar UNA iteraciÃ³n completa de _cfr_step_pure
print(f"\nğŸš€ Ejecutando _cfr_step_pure completo...")
key = jax.random.PRNGKey(42)

# CRITICAL: Llamar la funciÃ³n REAL de training
updated_regrets, updated_strategy = _cfr_step_pure(regrets, strategy, key, config)

print(f"\nğŸ“ˆ Info Set {target_info_set} despuÃ©s de 1 iteraciÃ³n:")
final_regrets = updated_regrets[target_info_set]
regret_changes = final_regrets - initial_regrets

actions = ["FOLD", "CHECK", "CALL", "BET_SMALL", "BET_MED", "BET_LARGE", "RAISE_SMALL", "RAISE_MED", "ALL_IN"]

print(f"ğŸ“Š Cambios en regrets:")
for action, change in zip(actions, regret_changes):
    print(f"  {action:12}: {change:8.6f}")

# Verificar magnitud esperada
fold_change = regret_changes[0]
expected_change = 2.311 * 0.02  # action_value Ã— learning_rate

print(f"\nğŸš¨ VerificaciÃ³n final:")
print(f"  Expected FOLD change: ~{expected_change:.6f}")
print(f"  Actual FOLD change: {fold_change:.6f}")
print(f"  Ratio: {fold_change/expected_change if expected_change != 0 else 'N/A':.3f}")

if abs(fold_change - expected_change) < 0.01:
    print(f"  âœ… Learning rate se aplica correctamente!")
    print(f"  â¡ï¸  El problema debe ser SPARSITY (pocas visitas)")
else:
    print(f"  âŒ Learning rate aÃºn no se aplica!")
    print(f"  â¡ï¸  Hay un bug mÃ¡s profundo en el training loop")

# Additional analysis: cuÃ¡ntos info sets fueron afectados
non_zero_changes = jnp.sum(jnp.any(jnp.abs(updated_regrets - regrets) > 0.001, axis=1))
print(f"\nğŸ“Š EstadÃ­sticas de la iteraciÃ³n:")
print(f"  Info sets modificados: {non_zero_changes}")
print(f"  Info sets totales: {regrets.shape[0]}")
print(f"  Cobertura por iteraciÃ³n: {non_zero_changes/regrets.shape[0]*100:.2f}%")

# Verificar si nuestro info set especÃ­fico fue tocado
info_set_touched = jnp.any(jnp.abs(regret_changes) > 0.001)
print(f"  Info set {target_info_set} fue modificado: {info_set_touched}")

if info_set_touched:
    print(f"  âœ… El info set SÃ se entrenÃ³ en esta iteraciÃ³n")
else:
    print(f"  âŒ El info set NO se entrenÃ³ (SPARSITY confirmado)")